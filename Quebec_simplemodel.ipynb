{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f58ef6e",
   "metadata": {},
   "source": [
    "# Electricity demand in Quebec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a2df7",
   "metadata": {},
   "source": [
    "We now focus on electricity consumption in Quebec.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93288acc",
   "metadata": {},
   "source": [
    "## Hydro-Québec open data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2428ae",
   "metadata": {},
   "source": [
    "Since 2019, Hydro-Québec shares data on various aspects regarding its operations, at the page https://www.hydroquebec.com/documents-data/open-data/.\n",
    "\n",
    "Here, we are interested in the historical demand: https://www.hydroquebec.com/documents-data/open-data/history-electricity-demand-quebec/. In particular, we can track the hourly total demand in Quebec, noting that\n",
    "> Electricity demand for one hour corresponds to the total average demand during that hour.\n",
    "\n",
    "> The data is determined at the end of a time period. For example, the average hourly demand associated with 2019‑01‑01 2:00 is the average of the data collected from 2019‑01‑01 1:05 to 2019‑01‑01 2:00."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a5a50",
   "metadata": {},
   "source": [
    "We will analyze the data using Pandas and Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcffa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664a90d",
   "metadata": {},
   "source": [
    "## A first forecasting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4c12c",
   "metadata": {},
   "source": [
    "The model we will built is highly simplified as the total Quebec consumption is taken into account, along with a single weather station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75839df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "from data.get_data import HQ_data\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "class Fourier_series:\n",
    "\n",
    "    def get_predictions(self, data, train_start, train_end, test):\n",
    "\n",
    "        pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "        data = data.loc[train_start:test, :].copy()\n",
    "\n",
    "        # get fourier series features\n",
    "        ff_week = self.get_fourier_features(5, 7, data.loc[:, \"day\"])\n",
    "        ff_24h = self.get_fourier_features(5, 24, data.loc[:, \"hour\"])\n",
    "        fourier_features = pd.concat([ff_week, ff_24h], ignore_index=True, axis=1)\n",
    "\n",
    "        # add extra predictors\n",
    "        features = [\"scaled_temp\", \"temp_lag_15\", \"temp_index_15\", \n",
    "                    \"demand_lag_24\", \"is_clear\", \"rel_hum\", \"scaled_temp_diff_24\", \"scaled_temp_diff_48\"]\n",
    "\n",
    "        X = fourier_features\n",
    "        X[features] = data.loc[:, features]\n",
    "        X.columns = X.columns.astype(str)\n",
    "        \n",
    "        # train model\n",
    "\n",
    "        X_train = pf.fit_transform(X.loc[train_start:train_end, :])\n",
    "        y_train = data.loc[train_start:train_end, \"log_demand\"]\n",
    "\n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "        # get forecast\n",
    "        X_test = pf.fit_transform(np.array(X.loc[test, :]).reshape(1, -1))\n",
    "        forecast  = np.exp(model.predict(X_test))\n",
    "\n",
    "        return forecast\n",
    "    \n",
    "\n",
    "    def get_fourier_features(self, n_order, period, values):\n",
    "        fourier_features = pd.DataFrame(\n",
    "            {\n",
    "                f\"fourier_{func}_order_{order}_{period}\": getattr(np, func)(\n",
    "                    2 * order * np.pi * values / period\n",
    "                )\n",
    "                for order in range(1, n_order + 1)\n",
    "                for func in (\"sin\", \"cos\")\n",
    "            }\n",
    "        )\n",
    "        return fourier_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.get_data import HQ_data\n",
    "from models.regression_splines import SplineRegression\n",
    "# from models.fourier_series import Fourier_series\n",
    "from models.arma import ARMA_model\n",
    "from models.mlp import MLP_model\n",
    "\n",
    "class Simulation:\n",
    "\n",
    "    def __init__(self, num_iters, train_start, train_end):\n",
    "\n",
    "        self.num_iters = num_iters\n",
    "        self.train_start = train_start\n",
    "        self.train_end = train_end\n",
    "        self.test = self.train_end + datetime.timedelta(days=1)\n",
    "        self.data = HQ_data()\n",
    "        self.data = self.data.get_history()\n",
    "\n",
    "    def get_prediction(self, train_start, train_end, test):\n",
    "\n",
    "        \"\"\" \n",
    "        Implement algorithm or call model here. \n",
    "        Model should have get_predictions method that takes in data, train_start, train_end, test \n",
    "        and returns a single forecast for the time step test: 24 hour after train_end\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"mlp = MLP_model()\n",
    "        forecasts = mlp.get_predictions(self.data, train_start, train_end, test)\"\"\"\n",
    "\n",
    "        \"\"\"spline_reg = SplineRegression()\n",
    "        forecasts = spline_reg.get_predictions(self.data, train_start, train_end, test)\"\"\"\n",
    "\n",
    "        fourier = Fourier_series()\n",
    "        forecasts = fourier.get_predictions(self.data, train_start, train_end, test)\n",
    "\n",
    "        \"\"\"arma = ARMA_model()\n",
    "        forecasts = arma.get_predictions(self.data, train_start, train_end, test)\"\"\"\n",
    "\n",
    "        return forecasts\n",
    "\n",
    "    def run_simulation(self):\n",
    "        \n",
    "        train_start = self.train_start\n",
    "        train_end = self.train_end\n",
    "        test = self.test\n",
    "\n",
    "        forecasts = []\n",
    "\n",
    "        for i in range(self.num_iters):\n",
    "\n",
    "            forecast = self.get_prediction(train_start, train_end, test)\n",
    "            forecasts.append(forecast)\n",
    "\n",
    "            print(\"********************************************\")\n",
    "            print(\"At iteration \"+ str(i))\n",
    "            print(\"forecast: \", forecast)\n",
    "            print(\"********************************************\")\n",
    "\n",
    "            # We increment the various times by one hour.\n",
    "            train_start = train_start + datetime.timedelta(hours=1)\n",
    "            train_end = train_end + datetime.timedelta(hours=1)\n",
    "            test = test + datetime.timedelta(hours=1)\n",
    "\n",
    "        return np.array(forecasts).flatten()\n",
    "\n",
    "    def plot_sim_results(self, forecasts):\n",
    "\n",
    "        sim_start = self.train_end + datetime.timedelta(days=1)\n",
    "        sim_end = sim_start + datetime.timedelta(hours = self.num_iters) - datetime.timedelta(hours=1)\n",
    "\n",
    "        results = self.data.loc[sim_start:sim_end, [\"demand\", \"scaled_temp\"]]\n",
    "        results[\"forecast\"] = forecasts\n",
    "\n",
    "        # save forecasts to csv\n",
    "        results.to_csv(\"results\\\\results_fourier_2021.csv\")\n",
    "\n",
    "        residuals = results.loc[:, \"demand\"] - results.loc[:, \"forecast\"]\n",
    "\n",
    "        print(\"RMSE\")\n",
    "        print(np.sqrt(np.mean(residuals**2)))\n",
    "\n",
    "        print(\"MAPE\")\n",
    "        print(np.mean(abs(residuals)/results.loc[:, \"demand\"]))\n",
    "\n",
    "        print(\"Percentage within 1000 mwh\")\n",
    "        print(sum(list(map(lambda x: int(x <= 1000), abs(residuals))))/len(residuals))\n",
    "\n",
    "        print(\"Percentage within 500 mwh\")\n",
    "        print(sum(list(map(lambda x: int(x <= 500), abs(residuals))))/len(residuals))\n",
    "\n",
    "        plt.plot(results.loc[:, \"demand\"], label=\"Demand\")\n",
    "        plt.plot(results.loc[:, \"forecast\"], label=\"Forecast\")\n",
    "        plt.legend()\n",
    "        plt.title(\"24 hour ahead energy demand forecast for year 2022\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34268321",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = datetime.datetime(2019, 1, 1, 0, 0, 0)\n",
    "train_end = datetime.datetime(2020, 12, 31, 23, 0, 0)\n",
    "\n",
    "# We train the model at each hour increment, for 365 days.\n",
    "sim = Simulation(365 * 24, train_start, train_end)\n",
    "forecasts = sim.run_simulation()\n",
    "sim.plot_sim_results(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot_sim_results(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e1b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
